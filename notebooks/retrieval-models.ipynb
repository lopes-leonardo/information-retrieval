{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bffdc074-8dbe-4018-ad36-b596306e8d95",
   "metadata": {},
   "source": [
    "# Retrieval models\n",
    "This notebook aims to implement the classical retrieval models based on tokenized texts and a defined word corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e6ad1f-fe11-476e-93b7-ac79bdc5595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "from abc import ABC, abstractmethod\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2c915a-88b6-42b6-9fe3-6378e4a8fc47",
   "metadata": {},
   "source": [
    "## Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2edca7f9-5882-43d2-8030-a24bbc1efd0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2423"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_corpus = pd.read_csv(\"../datasets/20news-word-corpus-2k.csv\")\n",
    "test_filter = np.load(\"../datasets/test_filter.npy\")\n",
    "classes = np.load(\"../datasets/20-news-classes.npy\")\n",
    "with open(\"../datasets/20-news-processed-no-singles.pickle\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)\n",
    "len(word_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f598db80-1121-46d1-ab8f-10bfded08a06",
   "metadata": {},
   "source": [
    "## Evaluation class\n",
    "\n",
    "A class to compute P@10, P@20, P@50, P@100 e MAP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44458186-b9e2-4fe7-8504-0eca0af27636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalEvaluation:\n",
    "    \n",
    "    def __init__(self, ranked_lists:np.ndarray, classes:np.ndarray):\n",
    "        self.ranked_lists = ranked_lists\n",
    "        self.classes = classes\n",
    "        self.class_size = 1000\n",
    "        self.n = len(ranked_lists)\n",
    "        \n",
    "    def p_at_n(self, n:int)->float:\n",
    "        p_total = 0\n",
    "        for rank in self.ranked_lists:\n",
    "            p = 0\n",
    "            target_class = self.classes[rank[0]]\n",
    "            for i in range(n):\n",
    "                if self.classes[rank[i]] == target_class:\n",
    "                    p += 1\n",
    "            p = p / n\n",
    "            p_total += p\n",
    "        return p_total / self.n\n",
    "    \n",
    "    def p_at_10(self)->float:\n",
    "        return self.p_at_n(n=10)\n",
    "    \n",
    "    def p_at_20(self)->float:\n",
    "        return self.p_at_n(n=20)\n",
    "    \n",
    "    def p_at_50(self)->float:\n",
    "        return self.p_at_n(n=50)\n",
    "    \n",
    "    def p_at_100(self)->float:\n",
    "        return self.p_at_n(n=100)\n",
    "    \n",
    "    def computeAveragePrecision(self, rk, d=1000):\n",
    "        sumrj = 0\n",
    "        curPrecision = 0\n",
    "        sumPrecision = 0\n",
    "        qClass = self.classes[rk[0]]\n",
    "        for i in range(d):\n",
    "            imgi = rk[i]\n",
    "            imgiClass = self.classes[imgi]\n",
    "            if (qClass == imgiClass):\n",
    "                sumrj = sumrj + 1\n",
    "                posi = i + 1\n",
    "                curPrecision = sumrj / posi\n",
    "                sumPrecision += curPrecision\n",
    "        nRel = self.class_size\n",
    "        l = len(rk)\n",
    "        avgPrecision = sumPrecision / min(l, nRel)\n",
    "        return avgPrecision\n",
    "\n",
    "    def compute_map(self):\n",
    "        acumAP = 0\n",
    "        for rk in self.ranked_lists:\n",
    "            acumAP += self.computeAveragePrecision(rk)\n",
    "        return acumAP / self.n\n",
    "    \n",
    "    def evaluate_all(self) -> None:\n",
    "        print(\"=========== Evaluation Procedure ===========\")\n",
    "        print(\"Evaluation dataset size:\", self.n)\n",
    "        print(\"Precision at 10:\", self.p_at_10())\n",
    "        print(\"Precision at 20:\", self.p_at_20())\n",
    "        print(\"Precision at 50:\", self.p_at_50())\n",
    "        print(\"Precision at 100:\", self.p_at_100())\n",
    "        print(\"Map:\", self.compute_map())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1f3eb-5d0f-4ec1-8ee8-27b6299b68f9",
   "metadata": {},
   "source": [
    "## The Retrieval model abstract class\n",
    "\n",
    "In order to facilitate the implementation of new models, we first create an AbstractClass to define the expected behavior of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ea4db3-abd6-4473-ae8b-6af557949cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorRetrievalModel(ABC):\n",
    " \n",
    "    def __init__(self, word_corpus: pd.DataFrame):\n",
    "        self.word_corpus = word_corpus.word.to_list()\n",
    "        # self.word_corpus.sort()\n",
    "        self.dataset = None\n",
    "        self.metric = None\n",
    "        super().__init__()\n",
    "    \n",
    "    def get_dataset(self) -> np.ndarray:\n",
    "        return self.dataset\n",
    "    \n",
    "    @abstractmethod\n",
    "    def convert_dataset(self, dataset:list):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def convert_item(self, item:list) -> list:\n",
    "        pass\n",
    "    \n",
    "    def compute_ranked_lists(self, metric:str = None, test_filter=None) -> np.ndarray:\n",
    "        if self.dataset is None:\n",
    "            raise Exception(\"No dataset has been defined, please create a new one with convert_dataset function.\")\n",
    "        \n",
    "        if self.metric is None:\n",
    "            raise Exception(\"No metric defined for the model.\")\n",
    "        \n",
    "        if metric is None:\n",
    "            metric = self.metric\n",
    "            \n",
    "        target_ranked_lists = self.dataset if test_filter is None else self.dataset[test_filter]\n",
    "            \n",
    "        \n",
    "        ranked_lists = []\n",
    "\n",
    "        if metric == \"cosine\":\n",
    "            distances = metrics.pairwise.cosine_distances(target_ranked_lists, self.dataset)\n",
    "        else:\n",
    "            distances = metrics.pairwise.euclidean_distances(target_ranked_lists, self.dataset)\n",
    "        \n",
    "        for item in distances:\n",
    "            rank_map = np.argsort(item)\n",
    "            ranked_lists.append(rank_map)\n",
    "        self.ranked_lists = np.asarray(ranked_lists)\n",
    "    \n",
    "    def get_ranked_lists(self) -> np.ndarray:\n",
    "        return self.ranked_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e218468e-850f-47e5-98de-854f78497ab8",
   "metadata": {},
   "source": [
    "## Binary model\n",
    "A vetor with values 1 or 0 for each word of the word corpus, representing if they are in the encoded text tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9af9d0e9-4675-4db6-8a1f-6f97355a6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryModel(VectorRetrievalModel):\n",
    "    \n",
    "    def __init__(self, word_corpus:pd.DataFrame):\n",
    "        super().__init__(word_corpus)\n",
    "        self.metric = 'cosine'\n",
    "        \n",
    "    def convert_dataset(self, dataset:list):\n",
    "        binary_dataset = []\n",
    "        for item in dataset:\n",
    "            binary_dataset.append(self.convert_item(item))\n",
    "        self.dataset = np.asarray(binary_dataset)\n",
    "    \n",
    "    def convert_item(self, item:list)-> list:\n",
    "        binary_item = []\n",
    "        for word in self.word_corpus:\n",
    "            value = 1 if word in item else 0\n",
    "            binary_item.append(value)\n",
    "        return binary_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cbe76c1-3f38-4543-9c78-786705620292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997, 2423)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_model = BinaryModel(word_corpus)\n",
    "binary_model.convert_dataset(dataset)\n",
    "binary_dataset = binary_model.get_dataset()\n",
    "binary_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02f0759c-3235-4d66-bab9-23d74d4d0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_ranked_list = binary_model.compute_ranked_lists()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e7b91b-14aa-49c3-bf92-4c4c22da5b27",
   "metadata": {},
   "source": [
    "## Evaluation test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ba7cf2-90c5-41cd-8442-1221b0965ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../datasets/20news-train-filtered.csv\")\n",
    "test = pd.read_csv(\"../datasets/20news-test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f9fcc5-f024-46c3-8a34-b6ee24f4bea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39ea758c-6ecc-4ad9-a6b8-b0261796892e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = train.category_id.to_list()\n",
    "test_ids = test.id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "88df00b6-a3a2-475a-a173-8e6b36fa50bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[12000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4d7c0ad-8171-4ee6-a540-7de63a98815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes = test.category_id.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3f661d3c-6e24-4668-979a-0207b8f78cf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19997"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train.id.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6dae2549-9e18-425a-9471-dfde5cb364f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_filter = train.id.isin(test_ids).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7c8bd750-6dfa-45aa-a965-d93fc8138f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ranked_lists = binary_ranked_list[test_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "22aa76f8-6bcd-4861-8027-defefc821a4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 19997)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ranked_lists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "881e6127-cd13-4156-8e59-5a5ac1ba1e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "rk = test_ranked_lists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "db877376-de8c-401c-9ec6-aee3884709a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = RetrievalEvaluation(np.asarray([test_ranked_lists[0]]), classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1cc6e915-388d-474a-b893-ed4ec56cabd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation.p_at_10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1fc9e887-06dc-4f9b-8689-b3dab44e7670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 -> 0\n",
      "1354 -> 1\n",
      "5303 -> 5\n",
      "13131 -> 13\n",
      "17633 -> 17\n",
      "8882 -> 8\n",
      "17488 -> 17\n",
      "17229 -> 17\n",
      "14280 -> 14\n",
      "17570 -> 17\n"
     ]
    }
   ],
   "source": [
    "rk = test_ranked_lists[0]\n",
    "for i in range(10):\n",
    "    print(rk[i], \"->\", classes[rk[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb30b7-8d5a-4a8f-bb4f-854ac133cd4c",
   "metadata": {},
   "source": [
    "## Bag-of-Words\n",
    "\n",
    "The bag of words model is an expansion of the binary model, where the text is represented by a vector containing the count of each word from the word corpus in the converted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0100feae-4022-4631-b368-34ba1160dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWordsModel(VectorRetrievalModel):\n",
    "    \n",
    "    def __init__(self, word_corpus:pd.DataFrame):\n",
    "        super().__init__(word_corpus)\n",
    "        self.metric = \"cosine\"\n",
    "        \n",
    "    def convert_dataset(self, dataset:list):\n",
    "        bow_dataset = []\n",
    "        for item in dataset:\n",
    "            bow_dataset.append(self.convert_item(item))\n",
    "        self.dataset = np.asarray(bow_dataset)\n",
    "    \n",
    "    def convert_item(self, item:list)-> list:\n",
    "        bow_item = []\n",
    "        for word in self.word_corpus:\n",
    "            bow_item.append(item.count(word))\n",
    "        return bow_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1d786aa-ea4c-4ce2-aff2-da328c06c5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997, 1289)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_model = BagOfWordsModel(word_corpus)\n",
    "bow_dataset = bow_model.convert_dataset(dataset)\n",
    "bow_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "061541e9-1bbb-4c09-bf65-296e1c0d1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../datasets/20-news-bow-model\", bow_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f33e4-e308-4ac7-a6b3-8e00106e9dcd",
   "metadata": {},
   "source": [
    "## TF-IDF model\n",
    "The TF-IDF model computes values for each word based on its ocurrence in each text, in the full corpus and in how many texts it appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "669439ef-170d-4fcf-a450-d4ed4ec5a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIdfModel(VectorRetrievalModel):\n",
    "    \n",
    "    def __init__(self, word_corpus:pd.DataFrame):\n",
    "        super().__init__(word_corpus)\n",
    "        self.metric = \"cosine\"\n",
    "    \n",
    "    def compute_idf(self, dataset:list):\n",
    "        word_idf = []\n",
    "        dataset_size = len(dataset)\n",
    "        for index, word in enumerate(self.word_corpus):\n",
    "            word_idf.append(0)\n",
    "            for item in dataset:\n",
    "                if word in item:\n",
    "                    word_idf[index] += 1\n",
    "            if word_idf[index] == 0:\n",
    "                continue\n",
    "            word_idf[index] = math.log(dataset_size/word_idf[index], 2)\n",
    "        self.word_idf = np.asarray(word_idf)\n",
    "        \n",
    "    def convert_dataset(self, dataset:list):\n",
    "        # Calcular o idf para cada palavra.\n",
    "        self.compute_idf(dataset)\n",
    "        \n",
    "        tf_idf_dataset = []\n",
    "        for item in dataset:\n",
    "            tf_idf_dataset.append(self.convert_item(item))\n",
    "        self.dataset = np.asarray(tf_idf_dataset)\n",
    "    \n",
    "    def compute_tf(self, word:str, item:list):\n",
    "        word_count = item.count(word)\n",
    "        if word_count == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1 + math.log(word_count, 2)\n",
    "    \n",
    "    def convert_item(self, item:list)-> list:\n",
    "        tf_idf_item = []\n",
    "        for index, word in enumerate(self.word_corpus):\n",
    "            tf = self.compute_tf(word, item)\n",
    "            tf_idf = tf * self.word_idf[index]\n",
    "            tf_idf_item.append(tf_idf)\n",
    "        return tf_idf_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39571b55-110b-4063-938d-4171e77862ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../datasets/test_filter\", test_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67ac2aa2-c358-4cd0-9cdf-f9405cef94b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997, 2423)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_model = TfIdfModel(word_corpus)\n",
    "tf_idf_model.convert_dataset(dataset)\n",
    "tf_idf_dataset = tf_idf_model.get_dataset()\n",
    "tf_idf_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9abbd73-c938-45fe-9844-2129cc2a5ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_model.compute_ranked_lists(metric=\"cosine\", test_filter=test_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a07cea92-5b3e-419c-aede-1c47f2eae184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 19997)\n",
      "=========== Evaluation Procedure ===========\n",
      "Evaluation dataset size: 2000\n",
      "Precision at 10: 0.6672999999999998\n",
      "Precision at 20: 0.5894750000000006\n",
      "Precision at 50: 0.5045000000000003\n",
      "Precision at 100: 0.44692000000000015\n",
      "Map: 0.11126248061136677\n"
     ]
    }
   ],
   "source": [
    "ranked_lists = tf_idf_model.get_ranked_lists()\n",
    "print(ranked_lists.shape)\n",
    "evaluation = RetrievalEvaluation(ranked_lists, classes)\n",
    "evaluation.evaluate_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36ab16b2-146a-4a8e-8f3b-b858624ec0d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9987 -> 9\n",
      "9859 -> 9\n",
      "16783 -> 16\n",
      "9651 -> 9\n",
      "9368 -> 9\n",
      "10806 -> 10\n",
      "9315 -> 9\n",
      "10233 -> 10\n",
      "10214 -> 10\n",
      "10991 -> 10\n"
     ]
    }
   ],
   "source": [
    "rk = ranked_lists[999]\n",
    "for i in range(10):\n",
    "    print(rk[i], \"->\", classes[rk[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0b12db48-95ac-4fcc-aa93-2fb024d501ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../datasets/20-news-tf-idf-model\", tf_idf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1091e908-13f4-45b4-a3f1-d271dae72ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 19997)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset = tf_idf_model.get_dataset()\n",
    "test_a = test_dataset[0:10]\n",
    "distances = metrics.pairwise.cosine_distances(test_a, test_dataset)\n",
    "distances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d978f83-9541-434c-a634-5a6bd36b9fb1",
   "metadata": {},
   "source": [
    "## BM Models\n",
    "\n",
    "BM models are probalilistic models that take into account the size of each text, alongside other elements already demonstrated other elements explored in the models implemented above.\n",
    "\n",
    "Probabilitic models originally do not create a vector representation to each text in the corpus. They work as a direct computation between a query text and all the other texts in the corpus, retrieving a similarity score for each compared pair.\n",
    "\n",
    "In this implementation, the equation is computed for each word in the corpus, resulting in a vector with the value that would be sum in the original proposition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a8a9a-37f5-4e4d-afde-915a6ea19194",
   "metadata": {},
   "source": [
    "### BM1\n",
    "\n",
    "BM1 only takes into account the relation between all documents and in how many documents each term appears. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "316d02ab-c490-403c-b53a-547ce3c1ea9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM1Model(VectorRetrievalModel):\n",
    "    \n",
    "    def __init__(self, word_corpus:pd.DataFrame):\n",
    "        super().__init__(word_corpus)\n",
    "        self.metric = \"cosine\"\n",
    "    \n",
    "    def compute_idf(self, dataset:list):\n",
    "        word_idf = []\n",
    "        dataset_size = len(dataset)\n",
    "        for index, word in enumerate(self.word_corpus):\n",
    "            word_idf.append(0)\n",
    "            for item in dataset:\n",
    "                if word in item:\n",
    "                    word_idf[index] += 1\n",
    "            word_idf[index] = math.log((dataset_size - word_idf[index] + 0.5) / (word_idf[index] + 0.5), 2)\n",
    "        self.word_idf = np.asarray(word_idf)\n",
    "        \n",
    "    def convert_dataset(self, dataset:list):\n",
    "        # Calcular o idf para cada palavra.\n",
    "        self.compute_idf(dataset)\n",
    "        \n",
    "        tf_idf_dataset = []\n",
    "        for item in dataset:\n",
    "            tf_idf_dataset.append(self.convert_item(item))\n",
    "        self.dataset = np.asarray(tf_idf_dataset)\n",
    "    \n",
    "    def compute_tf(self, word:str, item:list):\n",
    "        word_count = item.count(word)\n",
    "        if word_count == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1 + math.log(word_count, 2)\n",
    "    \n",
    "    def convert_item(self, item:list)-> list:\n",
    "        tf_idf_item = []\n",
    "        for index, word in enumerate(self.word_corpus):\n",
    "            tf_idf = self.word_idf[index] if item.count(word) > 0 else 0\n",
    "            tf_idf_item.append(tf_idf)\n",
    "        return tf_idf_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a6cba9-1b9d-43ae-8bec-957d4f6a7992",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm1_model = BM1Model(word_corpus)\n",
    "bm1_model.convert_dataset(dataset)\n",
    "bm1_dataset = bm1_model.get_dataset()\n",
    "bm1_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f28f6cda-742b-455f-bc15-2127074f2528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.06394614, 1.76245565, 1.13712578, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm1_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55ef80f-f895-4a5f-9474-46c4cb67d449",
   "metadata": {},
   "source": [
    "### BM11\n",
    "\n",
    "BM11 Applies a term-factor that also takes into account the average size of the documents in the corpus, alonside with the size of the current document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d8fa818-ea98-4884-941c-39ef829542a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM11Model(VectorRetrievalModel):\n",
    "    \n",
    "    def __init__(self, word_corpus:pd.DataFrame, k1 = 1.0):\n",
    "        super().__init__(word_corpus)\n",
    "        self.metric = \"cosine\"\n",
    "        self.k1 = k1\n",
    "    \n",
    "    def compute_idf(self, dataset:list):\n",
    "        word_idf = []\n",
    "        dataset_size = len(dataset)\n",
    "        for index, word in enumerate(self.word_corpus):\n",
    "            word_idf.append(0)\n",
    "            for item in dataset:\n",
    "                if word in item:\n",
    "                    word_idf[index] += 1\n",
    "            word_idf[index] = math.log((dataset_size - word_idf[index] + 0.5) / (word_idf[index] + 0.5), 2)\n",
    "        self.word_idf = np.asarray(word_idf)\n",
    "        \n",
    "    def compute_average_size(self, dataset:list):\n",
    "        total_size = 0\n",
    "        for item in dataset:\n",
    "            total_size += len(item)\n",
    "        self.average_size = total_size / len(dataset)\n",
    "    \n",
    "    def convert_dataset(self, dataset:list):\n",
    "        # Calcular o idf para cada palavra.\n",
    "        self.compute_idf(dataset)\n",
    "        self.compute_average_size(dataset)\n",
    "        \n",
    "        tf_idf_dataset = []\n",
    "        for item in dataset:\n",
    "            tf_idf_dataset.append(self.convert_item(item))\n",
    "        self.dataset = np.asarray(tf_idf_dataset)\n",
    "    \n",
    "    def compute_tf(self, word:str, item:list, item_size:int):\n",
    "        word_count = item.count(word)\n",
    "        if word_count == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return ((self.k1 + 1) * word_count) / ((self.k1 * item_size / self.average_size) + word_count) \n",
    "    \n",
    "    def convert_item(self, item:list)-> list:\n",
    "        tf_idf_item = []\n",
    "        item_size = len(item)\n",
    "        for index, word in enumerate(self.word_corpus):\n",
    "            tf = self.compute_tf(word, item, item_size)\n",
    "            tf_idf = tf * self.word_idf[index] if item.count(word) > 0 else 0\n",
    "            tf_idf_item.append(tf_idf)\n",
    "        return tf_idf_item"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4dc23395-faf6-41d5-bd24-75df88824594",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646840b1-247a-4203-8bdd-f171b534dec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bm11_model = BM11Model(word_corpus)\n",
    "bm11_model.convert_dataset(dataset)\n",
    "bm11_dataset = bm11_model.get_dataset()\n",
    "bm11_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24c665cd-7f95-4aef-87c5-a73109814fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.26026642, 1.60517239, 0.27816789, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm11_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4211264d-00cd-42d3-9103-cb444b22ca09",
   "metadata": {},
   "source": [
    "### BM15\n",
    "\n",
    "BM15 removes BM11's analysis over the lenght of the documents, only using constant K1 in the tf statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9816e0c6-f470-4e45-82bb-a9f527b8fa42",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM15Model(VectorRetrievalModel):\n",
    "    \n",
    "    def __init__(self, word_corpus:pd.DataFrame, k1 = 1.0):\n",
    "        super().__init__(word_corpus)\n",
    "        self.metric = \"cosine\"\n",
    "        self.k1 = k1\n",
    "    \n",
    "    def compute_idf(self, dataset:list):\n",
    "        word_idf = []\n",
    "        dataset_size = len(dataset)\n",
    "        for index, word in enumerate(self.word_corpus):\n",
    "            word_idf.append(0)\n",
    "            for item in dataset:\n",
    "                if word in item:\n",
    "                    word_idf[index] += 1\n",
    "            word_idf[index] = math.log((dataset_size - word_idf[index] + 0.5) / (word_idf[index] + 0.5), 2)\n",
    "        self.word_idf = np.asarray(word_idf)\n",
    "        \n",
    "    def compute_average_size(self, dataset:list):\n",
    "        total_size = 0\n",
    "        for item in dataset:\n",
    "            total_size += len(item)\n",
    "        self.average_size = total_size / len(dataset)\n",
    "    \n",
    "    def convert_dataset(self, dataset:list):\n",
    "        # Calcular o idf para cada palavra.\n",
    "        self.compute_idf(dataset)\n",
    "        self.compute_average_size(dataset)\n",
    "        \n",
    "        tf_idf_dataset = []\n",
    "        for item in dataset:\n",
    "            tf_idf_dataset.append(self.convert_item(item))\n",
    "        self.dataset = np.asarray(tf_idf_dataset)\n",
    "    \n",
    "    def compute_tf(self, word:str, item:list):\n",
    "        word_count = item.count(word)\n",
    "        if word_count == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return ((self.k1 + 1) * word_count) / (self.k1 + word_count) \n",
    "    \n",
    "    def convert_item(self, item:list)-> list:\n",
    "        tf_idf_item = []\n",
    "        for index, word in enumerate(self.word_corpus):\n",
    "            tf = self.compute_tf(word, item)\n",
    "            tf_idf = tf * self.word_idf[index] if item.count(word) > 0 else 0\n",
    "            tf_idf_item.append(tf_idf)\n",
    "        return tf_idf_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "591a5b36-03e9-451c-9d48-51d3c0bb4dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997, 1289)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm15_model = BM15Model(word_corpus)\n",
    "bm15_model.convert_dataset(dataset)\n",
    "bm15_dataset = bm15_model.get_dataset()\n",
    "bm15_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "97bfdd8b-1bf2-485f-a4cc-ab4a0c0aebce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.06394614, 3.02135255, 1.13712578, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm15_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216bee17-db24-4d51-960e-609ed6af0476",
   "metadata": {},
   "source": [
    "### BM25\n",
    "\n",
    "BM25 is the combination of BM11 and BM15 based on a b (beta) constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a5247f80-932a-4aea-80b9-d924b259e614",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BM25Model(VectorRetrievalModel):\n",
    "    \n",
    "    def __init__(self, word_corpus:pd.DataFrame, k = 1.2, b = 0.8):\n",
    "        super().__init__(word_corpus)\n",
    "        self.metric = \"cosine\"\n",
    "        self.k = k\n",
    "        self.b = b\n",
    "    \n",
    "    def compute_idf(self, dataset:list):\n",
    "        word_idf = []\n",
    "        dataset_size = len(dataset)\n",
    "        for index, word in enumerate(self.word_corpus):\n",
    "            word_idf.append(0)\n",
    "            for item in dataset:\n",
    "                if word in item:\n",
    "                    word_idf[index] += 1\n",
    "            word_idf[index] = math.log((dataset_size - word_idf[index] + 0.5) / (word_idf[index] + 0.5), 2)\n",
    "        self.word_idf = np.asarray(word_idf)\n",
    "        \n",
    "    def compute_average_size(self, dataset:list):\n",
    "        total_size = 0\n",
    "        for item in dataset:\n",
    "            total_size += len(item)\n",
    "        self.average_size = total_size / len(dataset)\n",
    "    \n",
    "    def convert_dataset(self, dataset:list):\n",
    "        # Calcular o idf para cada palavra.\n",
    "        self.compute_idf(dataset)\n",
    "        self.compute_average_size(dataset)\n",
    "        \n",
    "        tf_idf_dataset = []\n",
    "        for item in dataset:\n",
    "            tf_idf_dataset.append(self.convert_item(item))\n",
    "        self.dataset = np.asarray(tf_idf_dataset)\n",
    "    \n",
    "    def compute_tf(self, word:str, item:list, item_size:int):\n",
    "        word_count = item.count(word)\n",
    "        if word_count == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            upper = (self.k + 1) * word_count\n",
    "            bottom = (self.k * (1 - self.b)) + (self.k * self.b * self.average_size / item_size) + word_count\n",
    "            return upper / bottom \n",
    "    \n",
    "    def convert_item(self, item:list)-> list:\n",
    "        tf_idf_item = []\n",
    "        item_size = len(item)\n",
    "        for index, word in enumerate(self.word_corpus):\n",
    "            tf = self.compute_tf(word, item, item_size)\n",
    "            tf_idf = tf * self.word_idf[index] if item.count(word) > 0 else 0\n",
    "            tf_idf_item.append(tf_idf)\n",
    "        return tf_idf_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01938d14-bada-460b-bbf1-08132c6d6425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997, 1289)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_model = BM25Model(word_corpus)\n",
    "bm25_model.convert_dataset(dataset)\n",
    "bm25_dataset = bm25_model.get_dataset()\n",
    "bm25_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "80d1b292-62c1-4b3f-8339-b0da38d7c9c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.57095946, 3.32825701, 1.67901216, ..., 0.        , 0.        ,\n",
       "       0.        ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bm25_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca23588-2ce4-4c0c-8371-5013b4bad191",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../datasets/20news-train-filtered.csv\")\n",
    "test = pd.read_csv(\"../datasets/20news-test.csv\")\n",
    "classes = train.category_id.to_list()\n",
    "test_ids = test.id.to_list()\n",
    "test_filter = train.id.isin(test_ids).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e9a068d-ed64-468e-9d53-1b2243b5dc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 19997)\n",
      "=========== Evaluation Procedure ===========\n",
      "Evaluation dataset size: 2000\n",
      "Precision at 10: 0.6366999999999985\n",
      "Precision at 20: 0.5548249999999999\n",
      "Precision at 50: 0.4652\n",
      "Precision at 100: 0.41125000000000095\n",
      "Map: 0.09621196917989455\n"
     ]
    }
   ],
   "source": [
    "bm25_model.compute_ranked_lists(metric=\"cosine\", test_filter=test_filter)\n",
    "ranked_lists = bm25_model.get_ranked_lists()\n",
    "print(ranked_lists.shape)\n",
    "evaluation = RetrievalEvaluation(ranked_lists, classes)\n",
    "evaluation.evaluate_all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "retrieval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
