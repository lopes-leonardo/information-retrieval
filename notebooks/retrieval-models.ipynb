{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bffdc074-8dbe-4018-ad36-b596306e8d95",
   "metadata": {},
   "source": [
    "# Retrieval models\n",
    "This notebook aims to implement the classical retrieval models based on tokenized texts and a defined word corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93e6ad1f-fe11-476e-93b7-ac79bdc5595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2c915a-88b6-42b6-9fe3-6378e4a8fc47",
   "metadata": {},
   "source": [
    "## Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2edca7f9-5882-43d2-8030-a24bbc1efd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_corpus = pd.read_csv(\"../datasets/20-news-word-corpus.csv\")\n",
    "with open(\"../datasets/20-news-processed-no-singles.pickle\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d7f2ef1-8a32-431f-b116-671ebcae23ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1289"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e218468e-850f-47e5-98de-854f78497ab8",
   "metadata": {},
   "source": [
    "## Binary model\n",
    "A vetor with values 1 or 0 for each word of the word corpus, representing if they are in the encoded text tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05f5ffb2-987f-4309-b51b-ce5ef3fcfcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(word_corpus: pd.DataFrame, dataset: list):\n",
    "    words = word_corpus.word.to_list()\n",
    "    binary_dataset = []\n",
    "    for item in dataset:\n",
    "        binary_item = []\n",
    "        for word in words:\n",
    "            value = 1 if word in item else 0\n",
    "            binary_item.append(value)\n",
    "        binary_dataset.append(binary_item)\n",
    "    return np.asarray(binary_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7cbe76c1-3f38-4543-9c78-786705620292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997, 1289)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_dataset = convert_to_binary(word_corpus, dataset)\n",
    "binary_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4554995d-0230-43fb-aaba-2849cbc79ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../datasets/20-news-binary-model\", binary_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb30b7-8d5a-4a8f-bb4f-854ac133cd4c",
   "metadata": {},
   "source": [
    "## Bag-of-Words\n",
    "\n",
    "The bag of words model is an expansion of the binary model, where the text is represented by a vector containing the count of each word from the word corpus in the converted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e95fc965-cd30-458f-8e58-af969aeb256c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_bag_of_words(word_corpus: pd.DataFrame, dataset: list):\n",
    "    words = word_corpus.word.to_list()\n",
    "    bow_dataset = []\n",
    "    for item in dataset:\n",
    "        bow_item = []\n",
    "        for word in words:\n",
    "            bow_item.append(item.count(word))\n",
    "        bow_dataset.append(bow_item)\n",
    "    return np.asarray(bow_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1d786aa-ea4c-4ce2-aff2-da328c06c5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997, 1289)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_dataset = convert_to_bag_of_words(word_corpus, dataset)\n",
    "bow_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "061541e9-1bbb-4c09-bf65-296e1c0d1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../datasets/20-news-bow-model\", bow_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f33e4-e308-4ac7-a6b3-8e00106e9dcd",
   "metadata": {},
   "source": [
    "## TF-IDF model\n",
    "The TF-IDF model computes values for each word based on its ocurrence in each text, in the full corpus and in how many texts it appears."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "retrieval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
