{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bffdc074-8dbe-4018-ad36-b596306e8d95",
   "metadata": {},
   "source": [
    "# Retrieval models\n",
    "This notebook aims to implement the classical retrieval models based on tokenized texts and a defined word corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "93e6ad1f-fe11-476e-93b7-ac79bdc5595f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import math\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2c915a-88b6-42b6-9fe3-6378e4a8fc47",
   "metadata": {},
   "source": [
    "## Dataset import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2edca7f9-5882-43d2-8030-a24bbc1efd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_corpus = pd.read_csv(\"../datasets/20-news-word-corpus.csv\")\n",
    "with open(\"../datasets/20-news-processed-no-singles.pickle\", \"rb\") as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d7f2ef1-8a32-431f-b116-671ebcae23ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1289"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a1f3eb-5d0f-4ec1-8ee8-27b6299b68f9",
   "metadata": {},
   "source": [
    "## The Retrieval model abstract class\n",
    "\n",
    "In order to facilitate the implementation of new models, we first create an AbstractClass to define the expected behavior of the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "13ea4db3-abd6-4473-ae8b-6af557949cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RetrievalModel(ABC):\n",
    " \n",
    "    def __init__(self, word_corpus: pd.DataFrame):\n",
    "        self.word_corpus = word_corpus\n",
    "        super().__init__()\n",
    "    \n",
    "    @abstractmethod\n",
    "    def convert_dataset(self, dataset:list):\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def convert_item(self, item:list):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e218468e-850f-47e5-98de-854f78497ab8",
   "metadata": {},
   "source": [
    "## Binary model\n",
    "A vetor with values 1 or 0 for each word of the word corpus, representing if they are in the encoded text tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9af9d0e9-4675-4db6-8a1f-6f97355a6b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryModel(RetrievalModel):\n",
    "    \n",
    "    def __init__(self, word_corpus:pd.DataFrame):\n",
    "        super().__init__(word_corpus)\n",
    "        self.word_corpus = word_corpus.word.to_list()\n",
    "        self.word_corpus.sort()\n",
    "        \n",
    "    def convert_dataset(self, dataset:list)-> np.ndarray:\n",
    "        binary_dataset = []\n",
    "        for item in dataset:\n",
    "            binary_dataset.append(self.convert_item(item))\n",
    "        return np.asarray(binary_dataset)\n",
    "    \n",
    "    def convert_item(self, item:list)-> list:\n",
    "        binary_item = []\n",
    "        for word in self.word_corpus:\n",
    "            value = 1 if word in item else 0\n",
    "            binary_item.append(value)\n",
    "        return binary_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f5ffb2-987f-4309-b51b-ce5ef3fcfcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_binary(word_corpus: pd.DataFrame, dataset: list):\n",
    "    words = word_corpus.word.to_list()\n",
    "    binary_dataset = []\n",
    "    for item in dataset:\n",
    "        binary_item = []\n",
    "        for word in words:\n",
    "            value = 1 if word in item else 0\n",
    "            binary_item.append(value)\n",
    "        binary_dataset.append(binary_item)\n",
    "    return np.asarray(binary_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cbe76c1-3f38-4543-9c78-786705620292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997, 1289)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_model = BinaryModel(word_corpus)\n",
    "binary_dataset = binary_model.convert_dataset(dataset)\n",
    "binary_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4554995d-0230-43fb-aaba-2849cbc79ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../datasets/20-news-binary-model\", binary_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbb30b7-8d5a-4a8f-bb4f-854ac133cd4c",
   "metadata": {},
   "source": [
    "## Bag-of-Words\n",
    "\n",
    "The bag of words model is an expansion of the binary model, where the text is represented by a vector containing the count of each word from the word corpus in the converted text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0100feae-4022-4631-b368-34ba1160dae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfWordsModel(RetrievalModel):\n",
    "    \n",
    "    def __init__(self, word_corpus:pd.DataFrame):\n",
    "        super().__init__(word_corpus)\n",
    "        self.word_corpus = word_corpus.word.to_list()\n",
    "        self.word_corpus.sort()\n",
    "        \n",
    "    def convert_dataset(self, dataset:list)-> np.ndarray:\n",
    "        bow_dataset = []\n",
    "        for item in dataset:\n",
    "            bow_dataset.append(self.convert_item(item))\n",
    "        return np.asarray(bow_dataset)\n",
    "    \n",
    "    def convert_item(self, item:list)-> list:\n",
    "        bow_item = []\n",
    "        for word in self.word_corpus:\n",
    "            bow_item.append(item.count(word))\n",
    "        return bow_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f1d786aa-ea4c-4ce2-aff2-da328c06c5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997, 1289)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_model = BagOfWordsModel(word_corpus)\n",
    "bow_dataset = bow_model.convert_dataset(dataset)\n",
    "bow_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "061541e9-1bbb-4c09-bf65-296e1c0d1b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../datasets/20-news-bow-model\", bow_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f33e4-e308-4ac7-a6b3-8e00106e9dcd",
   "metadata": {},
   "source": [
    "## TF-IDF model\n",
    "The TF-IDF model computes values for each word based on its ocurrence in each text, in the full corpus and in how many texts it appears."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "669439ef-170d-4fcf-a450-d4ed4ec5a319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfIdfModel(RetrievalModel):\n",
    "    \n",
    "    def __init__(self, word_corpus:pd.DataFrame):\n",
    "        super().__init__(word_corpus)\n",
    "        self.word_corpus = word_corpus.word.to_list()\n",
    "        self.word_corpus.sort()\n",
    "    \n",
    "    def compute_idf(self, dataset:list):\n",
    "        word_idf = []\n",
    "        dataset_size = len(dataset)\n",
    "        for index, word in enumerate(self.word_corpus):\n",
    "            word_idf.append(0)\n",
    "            for item in dataset:\n",
    "                if word in item:\n",
    "                    word_idf[index] += 1\n",
    "            if word_idf[index] == 0:\n",
    "                continue\n",
    "            word_idf[index] = math.log(dataset_size/word_idf[index], 2)\n",
    "        self.word_idf = np.asarray(word_idf)\n",
    "        \n",
    "    def convert_dataset(self, dataset:list)-> np.ndarray:\n",
    "        # Calcular o idf para cada palavra.\n",
    "        self.compute_idf(dataset)\n",
    "        \n",
    "        tf_idf_dataset = []\n",
    "        for item in dataset:\n",
    "            tf_idf_dataset.append(self.convert_item(item))\n",
    "        return np.asarray(tf_idf_dataset)\n",
    "    \n",
    "    def compute_tf(self, word:str, item:list):\n",
    "        word_count = item.count(word)\n",
    "        if word_count == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1 + math.log(word_count, 2)\n",
    "    \n",
    "    def convert_item(self, item:list)-> list:\n",
    "        tf_idf_item = []\n",
    "        for index, word in enumerate(self.word_corpus):\n",
    "            tf = self.compute_tf(word, item)\n",
    "            tf_idf = tf * self.word_idf[index]\n",
    "            tf_idf_item.append(tf_idf)\n",
    "        return tf_idf_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "67ac2aa2-c358-4cd0-9cdf-f9405cef94b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19997, 1289)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_model = TfIdfModel(word_corpus)\n",
    "tf_idf_dataset = tf_idf_model.convert_dataset(dataset)\n",
    "tf_idf_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e88878be-d94a-43ba-b94c-3c10ffe644ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for item in dataset:\n",
    "    if 'atheist' in item:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f4b89caa-59dc-4d12-909d-549c0ee1f08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.92532467532467"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "19997/308"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cd5caf71-c50b-4bbb-a0c5-f5b7c3df8d0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.819890408978376"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.log(19997/1416, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "754fa307-3dda-4ac9-a887-b957461c22e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abl\n",
      "3.819890408978376\n"
     ]
    }
   ],
   "source": [
    "model = tf_idf_model\n",
    "print(model.word_corpus[12])\n",
    "print(model.word_idf[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c674dc68-5b59-4e05-bda8-186e495c641a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 + math.log(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4082a7c8-3cff-4bb6-a344-8cafec12ceb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_dataset[1][105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "46c18bb5-30fa-4d8d-872a-3e33dbef2632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'atheist'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.word_corpus[105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "de9effbd-8e79-494c-a751-e9bcbbf923b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45.10627049809009"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_dataset[1][105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0b12db48-95ac-4fcc-aa93-2fb024d501ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"../datasets/20-news-tf-idf-model\", tf_idf_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "retrieval",
   "language": "python",
   "name": "retrieval"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
